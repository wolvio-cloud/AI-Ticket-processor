"""
Real-Time AI Ticket Processor Dashboard
Professional dashboard with PII compliance, industry breakdown, and cost savings
"""

import streamlit as st
import plotly.graph_objects as go
import plotly.express as px
import pandas as pd
import json
from datetime import datetime, timedelta
from pathlib import Path
import time

# ============================================================================
# PAGE CONFIGURATION
# ============================================================================

st.set_page_config(
    page_title="AI Ticket Processor - Real-Time Dashboard",
    page_icon="ğŸ«",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================================
# CUSTOM STYLING
# ============================================================================

st.markdown("""
<style>
    /* Main metrics cards */
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 10px;
        color: white;
        text-align: center;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }

    /* Success/danger indicators */
    .success-badge {
        background-color: #10b981;
        color: white;
        padding: 5px 15px;
        border-radius: 20px;
        font-weight: bold;
    }
    .warning-badge {
        background-color: #f59e0b;
        color: white;
        padding: 5px 15px;
        border-radius: 20px;
        font-weight: bold;
    }
    .danger-badge {
        background-color: #ef4444;
        color: white;
        padding: 5px 15px;
        border-radius: 20px;
        font-weight: bold;
    }

    /* PII compliance badge */
    .pii-badge {
        background: linear-gradient(90deg, #06b6d4 0%, #3b82f6 100%);
        color: white;
        padding: 10px 20px;
        border-radius: 10px;
        display: inline-block;
        margin: 10px 0;
        font-weight: bold;
    }

    /* Headers */
    h1 { color: #1f2937; }
    h2 { color: #374151; border-bottom: 2px solid #e5e7eb; padding-bottom: 10px; }
    h3 { color: #4b5563; }

    /* Metric value styling */
    [data-testid="stMetricValue"] {
        font-size: 2rem;
        font-weight: 700;
    }
</style>
""", unsafe_allow_html=True)

# ============================================================================
# DATA LOADING FUNCTIONS
# ============================================================================

@st.cache_data(ttl=30)  # Cache for 30 seconds (real-time refresh)
def load_latest_results():
    """Load the most recent results from JSON files"""
    logs_dir = Path("logs")
    results = []

    # Get all results files sorted by modification time
    result_files = sorted(logs_dir.glob("results_*.json"), key=lambda x: x.stat().st_mtime, reverse=True)

    # Load last 10 runs for timeline
    for file in result_files[:10]:
        try:
            with open(file, 'r') as f:
                data = json.load(f)
                # Add filename for identification
                data['filename'] = file.stem
                # Parse timestamp from filename
                date_str = file.stem.split('_')[1] + file.stem.split('_')[2]
                data['timestamp'] = datetime.strptime(date_str, "%Y%m%d%H%M%S")
                results.append(data)
        except Exception as e:
            st.error(f"Error loading {file.name}: {e}")

    return results

def calculate_metrics(results):
    """Calculate comprehensive metrics from results"""
    if not results:
        return None

    # Latest run
    latest = results[0]

    # Aggregate stats
    total_processed = sum(r.get('processed', 0) for r in results)
    total_failed = sum(r.get('failed', 0) for r in results)
    total_tickets = total_processed + total_failed

    # Processing times
    processing_times = []
    for r in results:
        for ticket in r.get('results', []):
            if ticket.get('success'):
                processing_times.append(ticket.get('processing_time', 0))

    avg_time = sum(processing_times) / len(processing_times) if processing_times else 0

    # Success rate
    success_rate = (total_processed / total_tickets * 100) if total_tickets > 0 else 0

    # Cost calculation
    cost_per_ticket = 0.001  # $0.001 per ticket
    total_cost = total_tickets * cost_per_ticket

    # Manual cost comparison
    manual_cost_per_ticket = (5 / 60) * 50  # 5 min * $50/hour
    manual_total_cost = total_tickets * manual_cost_per_ticket
    cost_savings = manual_total_cost - total_cost

    # PII stats
    pii_protected_count = 0
    pii_redaction_types = {}

    for r in results:
        for ticket in r.get('results', []):
            analysis = ticket.get('analysis', {})
            if analysis.get('pii_redacted'):
                pii_protected_count += 1
                redactions = analysis.get('redactions', {})
                for pii_type, count in redactions.items():
                    pii_redaction_types[pii_type] = pii_redaction_types.get(pii_type, 0) + count

    # Industry breakdown (detect from categories)
    industry_counts = {'ecommerce': 0, 'saas': 0, 'general': 0}
    category_counts = {}
    urgency_counts = {}
    sentiment_counts = {}

    for r in results:
        for ticket in r.get('results', []):
            if ticket.get('success'):
                analysis = ticket.get('analysis', {})

                # Category
                category = analysis.get('root_cause', 'other')
                category_counts[category] = category_counts.get(category, 0) + 1

                # Industry classification (based on category keywords)
                if category in ['delivery_issue', 'product_defect', 'refund_request', 'order_cancellation']:
                    industry_counts['ecommerce'] += 1
                elif category in ['bug', 'feature', 'integration']:
                    industry_counts['saas'] += 1
                else:
                    industry_counts['general'] += 1

                # Urgency
                urgency = analysis.get('urgency', 'unknown')
                urgency_counts[urgency] = urgency_counts.get(urgency, 0) + 1

                # Sentiment
                sentiment = analysis.get('sentiment', 'unknown')
                sentiment_counts[sentiment] = sentiment_counts.get(sentiment, 0) + 1

    # Classification accuracy (% that are NOT "other")
    other_count = category_counts.get('other', 0)
    classified_count = sum(category_counts.values()) - other_count
    total_categories = sum(category_counts.values())
    classification_accuracy = (classified_count / total_categories * 100) if total_categories > 0 else 0

    # Draft generation metrics
    drafts_generated = 0
    drafts_failed = 0
    draft_word_counts = []
    sample_drafts = []

    for r in results:
        # Check if result has reply_drafts summary
        if 'reply_drafts' in r:
            drafts_generated += r['reply_drafts'].get('total_generated', 0)
            drafts_failed += r['reply_drafts'].get('failed', 0)

        # Collect sample drafts from individual tickets
        for ticket in r.get('results', []):
            if ticket.get('success'):
                analysis = ticket.get('analysis', {})
                if analysis.get('draft_status') == 'success':
                    draft_word_counts.append(analysis.get('draft_word_count', 0))
                    if len(sample_drafts) < 5:
                        sample_drafts.append({
                            'ticket_id': ticket.get('ticket_id'),
                            'draft': analysis.get('reply_draft', ''),
                            'word_count': analysis.get('draft_word_count', 0),
                            'category': analysis.get('root_cause', 'unknown')
                        })

    avg_draft_word_count = sum(draft_word_counts) / len(draft_word_counts) if draft_word_counts else 0
    draft_success_rate = (drafts_generated / (drafts_generated + drafts_failed) * 100) if (drafts_generated + drafts_failed) > 0 else 0

    return {
        'total_processed': total_processed,
        'total_failed': total_failed,
        'success_rate': success_rate,
        'avg_time': avg_time,
        'total_cost': total_cost,
        'manual_cost': manual_total_cost,
        'cost_savings': cost_savings,
        'pii_protected_count': pii_protected_count,
        'pii_redaction_types': pii_redaction_types,
        'drafts_generated': drafts_generated,
        'drafts_failed': drafts_failed,
        'draft_success_rate': draft_success_rate,
        'avg_draft_word_count': avg_draft_word_count,
        'sample_drafts': sample_drafts,
        'industry_counts': industry_counts,
        'category_counts': category_counts,
        'urgency_counts': urgency_counts,
        'sentiment_counts': sentiment_counts,
        'classification_accuracy': classification_accuracy,
        'latest_run': latest.get('timestamp'),
        'total_runs': len(results)
    }

def get_timeline_data(results):
    """Get timeline of processing runs"""
    timeline = []
    for r in results:
        timeline.append({
            'timestamp': r.get('timestamp'),
            'processed': r.get('processed', 0),
            'failed': r.get('failed', 0),
            'avg_time': sum(t.get('processing_time', 0) for t in r.get('results', [])) / max(len(r.get('results', [])), 1)
        })
    return pd.DataFrame(timeline).sort_values('timestamp')

# ============================================================================
# MAIN DASHBOARD
# ============================================================================

# Header with auto-refresh
col1, col2 = st.columns([3, 1])
with col1:
    st.title("ğŸ« AI Ticket Processor - Real-Time Dashboard")
    st.markdown("**Production-Ready Analytics** | GDPR & CCPA Compliant")

with col2:
    auto_refresh = st.checkbox("ğŸ”„ Auto-refresh (30s)", value=True)
    if auto_refresh:
        time.sleep(0.1)  # Small delay
        st.rerun()

st.markdown("---")

# Load data
results = load_latest_results()

if not results:
    st.warning("âš ï¸ No results found. Process some tickets first!")
    st.info("Run: `python Ai_ticket_processor.py --limit 10`")
    st.stop()

metrics = calculate_metrics(results)

# ============================================================================
# TOP METRICS ROW
# ============================================================================

col1, col2, col3, col4, col5 = st.columns(5)

with col1:
    st.metric(
        label="ğŸ“Š Total Processed",
        value=f"{metrics['total_processed']:,}",
        delta=f"{metrics['total_runs']} runs"
    )

with col2:
    st.metric(
        label="âœ… Success Rate",
        value=f"{metrics['success_rate']:.1f}%",
        delta="Excellent" if metrics['success_rate'] >= 99 else "Good" if metrics['success_rate'] >= 95 else "Needs Attention",
        delta_color="normal" if metrics['success_rate'] >= 99 else "inverse"
    )

with col3:
    st.metric(
        label="âš¡ Avg Time",
        value=f"{metrics['avg_time']:.2f}s",
        delta="vs 5 min manual",
        delta_color="normal"
    )

with col4:
    savings_pct = (metrics['cost_savings'] / metrics['manual_cost'] * 100) if metrics['manual_cost'] > 0 else 0
    st.metric(
        label="ğŸ’° Cost Savings",
        value=f"${metrics['cost_savings']:.2f}",
        delta=f"{savings_pct:.0f}% saved"
    )

with col5:
    st.metric(
        label="ğŸ”’ PII Protected",
        value=f"{metrics['pii_protected_count']}",
        delta="GDPR Compliant"
    )

st.markdown("---")

# ============================================================================
# PII COMPLIANCE SECTION
# ============================================================================

st.subheader("ğŸ”’ PII Protection & Compliance")

col1, col2 = st.columns([2, 1])

with col1:
    if metrics['pii_redaction_types']:
        st.markdown('<div class="pii-badge">âœ… GLOBALLY COMPLIANT: GDPR (EU) Â· CCPA (US) Â· Privacy Act (AU) Â· PIPEDA (CA)</div>', unsafe_allow_html=True)

        # PII redaction breakdown
        pii_df = pd.DataFrame(list(metrics['pii_redaction_types'].items()), columns=['PII Type', 'Redactions'])
        pii_df = pii_df.sort_values('Redactions', ascending=False)

        fig = go.Figure(data=[
            go.Bar(
                y=pii_df['PII Type'],
                x=pii_df['Redactions'],
                orientation='h',
                marker_color='#06b6d4',
                text=pii_df['Redactions'],
                textposition='auto',
            )
        ])
        fig.update_layout(
            title="PII Redactions by Type",
            height=300,
            showlegend=False,
            xaxis_title="Number of Redactions",
            yaxis_title=""
        )
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("No PII detected in processed tickets - All data is clean!")

with col2:
    st.markdown("### Protected PII Types (International)")
    st.markdown("""
    **Global Banking:**
    - ğŸ’³ Credit Cards
    - ğŸ¦ IBAN (EU)
    - ğŸ¦ Bank Accounts

    **US:**
    - ğŸ”¢ Social Security Numbers (SSN)
    - ğŸ¦ Routing Numbers

    **UK:**
    - ğŸ†” National Insurance (NI)
    - ğŸ¦ Sort Codes

    **Australia:**
    - ğŸ”¢ Tax File Numbers (TFN)
    - ğŸ¥ Medicare Numbers

    **Canada:**
    - ğŸ”¢ Social Insurance Numbers (SIN)

    **India:**
    - ğŸªª Aadhaar
    - ğŸ’¼ PAN Cards
    - ğŸ“ Phone Numbers
    - ğŸ¦ IFSC Codes

    **General:**
    - ğŸ“§ Emails (preserved by default)
    """)

    pii_protection_rate = (metrics['pii_protected_count'] / metrics['total_processed'] * 100) if metrics['total_processed'] > 0 else 0
    st.metric("PII Detection Rate", f"{pii_protection_rate:.1f}%")

# Regional PII Breakdown
if metrics['pii_redaction_types']:
    st.markdown("### ğŸŒ Regional PII Detection Breakdown")

    # Categorize PII by region
    regional_pii = {
        'US': 0,
        'UK': 0,
        'EU': 0,
        'Australia': 0,
        'Canada': 0,
        'India': 0,
        'Global': 0
    }

    for pii_type, count in metrics['pii_redaction_types'].items():
        if pii_type in ['us_ssn', 'us_routing']:
            regional_pii['US'] += count
        elif pii_type in ['uk_ni', 'uk_sort']:
            regional_pii['UK'] += count
        elif pii_type == 'iban':
            regional_pii['EU'] += count
        elif pii_type in ['au_medicare', 'au_tfn_ca_sin']:
            regional_pii['Australia'] += count
        elif pii_type in ['aadhaar', 'pan_card', 'ifsc', 'phone_india', 'phone_india_code']:
            regional_pii['India'] += count
        elif pii_type in ['credit_card', 'account_number', 'email']:
            regional_pii['Global'] += count

    # Filter out regions with no PII
    regional_pii_filtered = {k: v for k, v in regional_pii.items() if v > 0}

    if regional_pii_filtered:
        col1, col2 = st.columns([2, 1])

        with col1:
            # Pie chart for regional distribution
            fig_regional = go.Figure(data=[go.Pie(
                labels=list(regional_pii_filtered.keys()),
                values=list(regional_pii_filtered.values()),
                hole=.4,
                marker_colors=['#3b82f6', '#06b6d4', '#8b5cf6', '#f59e0b', '#10b981', '#ef4444', '#6366f1']
            )])
            fig_regional.update_layout(
                title="PII Detections by Region",
                height=250,
                showlegend=True
            )
            st.plotly_chart(fig_regional, use_container_width=True)

        with col2:
            st.markdown("#### Regional Totals")
            for region, count in sorted(regional_pii_filtered.items(), key=lambda x: x[1], reverse=True):
                st.markdown(f"**{region}:** {count} PII items")

st.markdown("---")

# ============================================================================
# REPLY DRAFT GENERATION
# ============================================================================

st.subheader("âœï¸  AI Reply Draft Generation")

col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric(
        label="ğŸ“ Drafts Generated",
        value=f"{metrics['drafts_generated']:,}",
        delta="Auto-generated"
    )

with col2:
    st.metric(
        label="âœ… Success Rate",
        value=f"{metrics['draft_success_rate']:.1f}%",
        delta="Excellent" if metrics['draft_success_rate'] >= 95 else "Good" if metrics['draft_success_rate'] >= 90 else "Needs Attention",
        delta_color="normal" if metrics['draft_success_rate'] >= 95 else "inverse"
    )

with col3:
    st.metric(
        label="ğŸ“Š Avg Word Count",
        value=f"{metrics['avg_draft_word_count']:.0f}",
        delta="words per draft"
    )

with col4:
    st.metric(
        label="âš ï¸  Failed",
        value=f"{metrics['drafts_failed']}",
        delta="Manual review needed" if metrics['drafts_failed'] > 0 else "None"
    )

# Sample drafts display
if metrics['sample_drafts']:
    st.markdown("### ğŸ“¨ Sample Reply Drafts (Last 5)")
    st.info("âš ï¸  These are AI-generated drafts. Review and edit before sending to customers.")

    for i, draft_data in enumerate(metrics['sample_drafts'], 1):
        with st.expander(f"Ticket #{draft_data['ticket_id']} - {draft_data['category']} ({draft_data['word_count']} words)"):
            st.markdown(f"**Draft Reply:**\n\n{draft_data['draft']}")
            st.caption("âœï¸  Review and personalize before sending")
else:
    st.info("No draft samples available yet. Process some tickets to see generated drafts!")

st.markdown("---")

# ============================================================================
# INDUSTRY & CLASSIFICATION ACCURACY
# ============================================================================

col1, col2 = st.columns(2)

with col1:
    st.subheader("ğŸ¢ Industry Breakdown")

    industry_df = pd.DataFrame(list(metrics['industry_counts'].items()), columns=['Industry', 'Count'])
    total_industry = industry_df['Count'].sum()
    industry_df['Percentage'] = (industry_df['Count'] / total_industry * 100).round(1)

    fig = go.Figure(data=[go.Pie(
        labels=industry_df['Industry'],
        values=industry_df['Count'],
        hole=.4,
        marker_colors=['#3b82f6', '#10b981', '#f59e0b'],
        textinfo='label+percent',
        textposition='outside'
    )])
    fig.update_layout(
        height=350,
        showlegend=True,
        legend=dict(orientation="h", yanchor="bottom", y=-0.2, xanchor="center", x=0.5)
    )
    st.plotly_chart(fig, use_container_width=True)

with col2:
    st.subheader("ğŸ¯ Classification Accuracy")

    accuracy = metrics['classification_accuracy']

    # Gauge chart for accuracy
    fig = go.Figure(go.Indicator(
        mode="gauge+number+delta",
        value=accuracy,
        title={'text': "Accuracy %"},
        delta={'reference': 90},
        gauge={
            'axis': {'range': [None, 100]},
            'bar': {'color': "#10b981"},
            'steps': [
                {'range': [0, 50], 'color': "#fecaca"},
                {'range': [50, 80], 'color': "#fde68a"},
                {'range': [80, 100], 'color': "#d1fae5"}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': 90
            }
        }
    ))
    fig.update_layout(height=350)
    st.plotly_chart(fig, use_container_width=True)

    if accuracy < 90:
        st.warning(f"âš ï¸ {metrics['category_counts'].get('other', 0)} tickets classified as 'other' - consider adding more industry-specific prompts")
    else:
        st.success(f"âœ… Excellent classification! Only {100-accuracy:.1f}% in 'other' category")

st.markdown("---")

# ============================================================================
# CATEGORY & SENTIMENT DISTRIBUTION
# ============================================================================

col1, col2 = st.columns(2)

with col1:
    st.subheader("ğŸ“ˆ Top Categories")

    # Sort and get top 10
    category_df = pd.DataFrame(list(metrics['category_counts'].items()), columns=['Category', 'Count'])
    category_df = category_df.sort_values('Count', ascending=True).tail(10)

    fig = go.Figure(data=[
        go.Bar(
            y=category_df['Category'],
            x=category_df['Count'],
            orientation='h',
            marker_color='#8b5cf6',
            text=category_df['Count'],
            textposition='auto',
        )
    ])
    fig.update_layout(height=400, showlegend=False, xaxis_title="Count")
    st.plotly_chart(fig, use_container_width=True)

with col2:
    st.subheader("ğŸ˜Š Sentiment Analysis")

    sentiment_df = pd.DataFrame(list(metrics['sentiment_counts'].items()), columns=['Sentiment', 'Count'])
    total_sentiment = sentiment_df['Count'].sum()

    colors_map = {
        'positive': '#10b981',
        'neutral': '#6b7280',
        'negative': '#ef4444'
    }
    colors = [colors_map.get(s, '#6b7280') for s in sentiment_df['Sentiment']]

    fig = go.Figure(data=[
        go.Bar(
            y=sentiment_df['Sentiment'],
            x=sentiment_df['Count'],
            orientation='h',
            marker_color=colors,
            text=[f"{c} ({c/total_sentiment*100:.0f}%)" for c in sentiment_df['Count']],
            textposition='auto',
        )
    ])
    fig.update_layout(height=400, showlegend=False, xaxis_title="Count")
    st.plotly_chart(fig, use_container_width=True)

    # Alert for negative sentiment
    negative_count = metrics['sentiment_counts'].get('negative', 0)
    negative_pct = (negative_count / total_sentiment * 100) if total_sentiment > 0 else 0
    if negative_pct > 30:
        st.error(f"ğŸš¨ High negative sentiment: {negative_pct:.0f}% - Immediate action required!")
    elif negative_pct > 20:
        st.warning(f"âš ï¸ Elevated negative sentiment: {negative_pct:.0f}% - Monitor closely")

st.markdown("---")

# ============================================================================
# PROCESSING TIMELINE
# ============================================================================

st.subheader("ğŸ“Š Processing Timeline (Last 10 Runs)")

timeline_df = get_timeline_data(results)

fig = go.Figure()

fig.add_trace(go.Scatter(
    x=timeline_df['timestamp'],
    y=timeline_df['processed'],
    name='Processed',
    line=dict(color='#10b981', width=3),
    fill='tozeroy'
))

fig.add_trace(go.Scatter(
    x=timeline_df['timestamp'],
    y=timeline_df['failed'],
    name='Failed',
    line=dict(color='#ef4444', width=2, dash='dash')
))

fig.update_layout(
    height=300,
    xaxis_title="Time",
    yaxis_title="Tickets",
    hovermode='x unified',
    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
)

st.plotly_chart(fig, use_container_width=True)

st.markdown("---")

# ============================================================================
# COST SAVINGS CALCULATOR
# ============================================================================

st.subheader("ğŸ’° ROI & Cost Savings Calculator")

col1, col2, col3 = st.columns(3)

with col1:
    tickets_per_month = st.number_input(
        "Estimated Tickets per Month",
        min_value=100,
        max_value=50000,
        value=1200,
        step=100
    )

with col2:
    manual_hourly_rate = st.number_input(
        "Manual Processing Hourly Rate ($)",
        min_value=20,
        max_value=200,
        value=50,
        step=5
    )

with col3:
    manual_minutes_per_ticket = st.number_input(
        "Manual Minutes per Ticket",
        min_value=1,
        max_value=30,
        value=5,
        step=1
    )

# Calculate ROI
manual_hours_month = (tickets_per_month * manual_minutes_per_ticket) / 60
manual_cost_month = manual_hours_month * manual_hourly_rate

ai_cost_month = tickets_per_month * 0.001  # $0.001 per ticket
ai_hours_month = (tickets_per_month * metrics['avg_time']) / 3600

monthly_savings = manual_cost_month - ai_cost_month
annual_savings = monthly_savings * 12
time_savings_pct = ((manual_hours_month - ai_hours_month) / manual_hours_month * 100)

# Display results
col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric("Manual Cost/Month", f"${manual_cost_month:,.2f}")
    st.caption(f"{manual_hours_month:.0f} hours")

with col2:
    st.metric("AI Cost/Month", f"${ai_cost_month:,.2f}")
    st.caption(f"{ai_hours_month:.2f} hours")

with col3:
    st.metric("Monthly Savings", f"${monthly_savings:,.2f}", delta=f"{(monthly_savings/manual_cost_month*100):.0f}% saved")

with col4:
    st.metric("Annual Savings", f"${annual_savings:,.2f}", delta=f"{time_savings_pct:.0f}% time saved")

st.markdown("---")

# ============================================================================
# FOOTER
# ============================================================================

col1, col2, col3 = st.columns(3)

with col1:
    st.markdown(f"**Last Updated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

with col2:
    st.markdown(f"**Latest Run:** {metrics['latest_run'].strftime('%Y-%m-%d %H:%M:%S') if metrics['latest_run'] else 'N/A'}")

with col3:
    status = "ğŸŸ¢ Operational" if metrics['success_rate'] >= 95 else "ğŸŸ¡ Warning" if metrics['success_rate'] >= 90 else "ğŸ”´ Degraded"
    st.markdown(f"**Status:** {status}")

# Sidebar info
with st.sidebar:
    st.header("âš™ï¸ Dashboard Settings")
    st.markdown("---")

    st.markdown("### ğŸ¯ Features")
    st.markdown("""
    - âœ… Real-time metrics
    - âœ… PII compliance tracking
    - âœ… AI reply draft generation
    - âœ… Industry breakdown
    - âœ… Cost savings calculator
    - âœ… Classification accuracy
    - âœ… Auto-refresh (30s)
    """)

    st.markdown("---")
    st.markdown("### ğŸ“Š About")
    st.markdown("""
    **AI Ticket Processor**
    Version 2.2 (Production)

    - OWASP Top 10 Compliant
    - GDPR & CCPA Ready
    - ISO 27001 Aligned
    - SOC 2 Type II Ready
    """)

    st.markdown("---")

    if st.button("ğŸ”„ Clear Cache & Refresh"):
        st.cache_data.clear()
        st.rerun()
